**analyze**
对句子设置倒排索引的方式
es默认自带的分词器

#Simple Analyzer – 按照非字母切分（符号被过滤），小写处理
#Stop Analyzer – 小写处理，停用词过滤（the，a，is）
#Whitespace Analyzer – 按照空格切分，不转小写
#Keyword Analyzer – 不分词，直接将输入当作输出
#Patter Analyzer – 正则表达式，默认 \W+ (非字符分隔)
#Language – 提供了30多种常见语言的分词器
#2 running Quick brown-foxes leap over lazy dogs in the summer evening

#standard（默认）
GET _analyze
{
  "analyzer": "standard",
  "text": "2 running Quick brown-foxes leap over lazy dogs in the summer evening."
}
通常这些自带的分词器无法满足我们的需求这个时候我们就需要自定义分词器

**character filters**
character filters 是一个过滤器
在tokenizer之前对文本进行处理，比如增加或删除以及替换字符串，
可以配置多个character filters

自带的character filters
**html strip -去除html标签**
POST _analyze
{
  "tokenizer":"keyword",
  "char_filter":{
    "type":"html_strip"
  },
  "text": "<b>hello world</b>"
}
POST _analyze
{
  "tokenizer":"keyword",
  "char_filter":{
    "type":"mapping",
    "mappings":["ello=>i"]
  },
  "text": "<b>hello world</b>"
}
**mapping  - 字符串替换**
POST _analyze
{
  "tokenizer":"keyword",
  "char_filter":{
    "type":"mapping",
    "mappings":["ello=>i"]
  },
  "text": "<b>hello world</b>"
}
**pattern replace  正则替换**
POST _analyze
{
  "tokenizer":"keyword",
  "char_filter":{
    "type":"pattern_replace",
    "pattern":"http://(.*)",
    "replacement":"$1"
  },
  "text": "http://www.baidu.com"
}



**tokenizer**
将文本按照一定的规则切分为token或者term，一种分词方式
自带的tokenizer
keyword  不切分看作一个整体

**standard 默认标准切词**
POST _analyze
{
  "tokenizer":{
    "type":"standard",
    "max_token_length":1  //每个切片最大长度为1
  },
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone"
}

whitespace 空格方式进行分词

path_hierarchy 路径方式进行分词
POST _analyze
{
  "tokenizer":"path_hierarchy",
  "text":"/user/ymruan/a/b/c/d/e"
}

uax_url_email  email方式进行分词
POST _analyze
{
  "tokenizer":{
    "type":"uax_url_email"
  },
  "text": "i want 1715776882@qq.com"
}

**Token Filters**
在tokenizer之后对输出的单词进行增删改查再加工

lowercase 转为小写
POST _analyze
{
  "tokenizer": "standard",
  "filter": ["lowercase"], 
    "text": ["I am felling :)", "Feeling :( today"]
}

stop 移除停用词
POST _analyze
{
  "tokenizer": "standard",
  "filter": ["lowercase","stop"], 
    "text": ["I a felling :)", "Feeling :( today"]
}

synoym 处理同义词
